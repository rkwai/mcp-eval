# Copy to .env and adjust to run against real APIs or invoke live LLM evals.

# REST API target when you swap the mock adapter for a live integration.
# API_BASE_URL=https://api.internal-support.local

# LLM evaluation defaults
LLM_PROVIDER=openai        # openai | openrouter | gemini
LLM_MODEL=gpt-4o-mini      # update to match the model you call
# LLM_TEMPERATURE=0
# LLM_MAX_TURNS=6

# Provider credentials (set the ones you intend to use)
LLM_PROVIDER_API_KEY=sk-your-api-key
LLM_PROVIDER_BASE_URL=https://api.example.com/v1/chat/completions
